{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrQVcF-ldGWQ"
   },
   "source": [
    "<h1> Soal 1: Pemahaman Tentang Model Evaluasi</h1>\n",
    "\n",
    "Jawab pertanyaan di bawah ini dengan bahasa masing-masing?\n",
    "\n",
    "1. Apa perbedaan antara data latih, data validasi, dan data test?\n",
    "2. Bagaimana cara kita menilai performa suatu model?\n",
    "3. Apa itu Confusion Matrix? Jelaskan secara lengkap!\n",
    "4. Apa itu Classification Report dari sklearn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sr6D5UIhgpwO"
   },
   "source": [
    "Jawab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. perbedaan antara data latih, data validasi, dan data test\n",
    "    - data latih adalah data yang digunakan mentraining model dengan mode .fit\n",
    "    - data test adalah data yang nantinya di prediksi dengan model untuk mengetahui kemampuan model dlam prediksi\n",
    "    - data validasi adalah data yang sesungguhnya dari hasil predik, data hasil predik akan dibandingkan oleh validasi untuk mengukur kemampuan deteksi dari model\n",
    "2. pada sklearn sendiri terdapat fitur2 metric yang digunakan untuk mengevaluasi model kita dalam memprediksi suatu data \n",
    "3. Confusion Matrix sebuah matrik yang mempresentasikan kemampuan model untuk memprediksi tiap klas target. Misal data positif dan negatif, hasil prediksi model terhadap memprediksi data itu tersebut positif atau negatif akan dianalisa berapa jumlah yang benar positif sebenarnya (True Positif), positif yang palsu (false positif), negatif yang benar (True negatif) dan negatif yang palsu (false negatif). kemudian di hitung presisi dan recall dari tiap kelas dan mencari f1score. Dari data-data tersebut akan dievaluasi bagaimana kemampuan model memprediksi pada masing-masing kelas\n",
    "4. sebuah fitur dari sklearn yang menampilkan beberapa kaslifikasi metric dari model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uY-s7-KDgrkV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fv2TVsgAdGWY"
   },
   "source": [
    "<h1>Soal 2: Aplikasi Model Evaluasi</h1>\n",
    "\n",
    "Kali ini kita akan menggunakan data untuk memprediksi kelangsungan hidup pasien yang telah mengalami operasi payudara. Dengan informasi yang dimiliki terkait pasien, kita akan membuat model untuk memprediksi apakah pasien akan bertahan hidup dalam waktu lebih dari 5 tahun atau tidak.\n",
    "\n",
    "Lebih Lengkapnya kalian bisa membaca informasi tentang dataset di link berikut: https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.names\n",
    "\n",
    "Buat model Klasifikasi (Model/Algoritma Bebas) untuk memprediksi status pasien dengan ketentuan sebagai berikut:\n",
    "\n",
    "1. Bagi kedua data ini menjadi data training dan data test dengan test_size=0.25.\n",
    "3. Pelajar tentang metrics roc_auc_score kemudian buatlah model dan evaluasi dengan menggunakan teknik cross-validation dengan scoring 'roc_auc'. Baca https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html untuk menggunakan metric roc_auc saat cross-validation.\n",
    "3. Berapa score rata2 dari model dengan teknik cross-validation tersebut?\n",
    "4. Prediksi data test dengan model yang telah kalian buat!\n",
    "5. Bagaimana hasil confusion matrix dari hasil prediksi tersebut?\n",
    "6. Bagaimana classification report dari hasil prediksi tersebut?\n",
    "5. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status positive?\n",
    "6. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status negatif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4UqaWyPdGWj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrbPNGtHdGXV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Patient's Years  N_positive_ax  survival_status\n",
       "0   30               64              1                1\n",
       "1   30               62              3                1\n",
       "2   30               65              0                1\n",
       "3   31               59              2                1\n",
       "4   31               65              4                1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dxYNPg7dGX4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    225\n",
       "2     81\n",
       "Name: survival_status, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['survival_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W2amvZgdGYX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286    2\n",
       "31     1\n",
       "72     1\n",
       "107    2\n",
       "88     1\n",
       "      ..\n",
       "268    2\n",
       "198    2\n",
       "302    1\n",
       "250    1\n",
       "240    2\n",
       "Name: survival_status, Length: 77, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# poin 1 : Memisahkan Data fitur dan data target serta membagi data trainig dan data test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('survival_status', axis=1)\n",
    "y = df['survival_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=21, stratify=y)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pembuatan metode algoritma\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "#Metode Multi layer prceptron\n",
    "mlp = MLPClassifier(solver='sgd', alpha=1e-6,activation='identity', batch_size=8,\n",
    "                    hidden_layer_sizes=(34), random_state=21, max_iter=2000, learning_rate_init=1e-6)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_tested_mlp = mlp.predict(X_test)\n",
    "y_tested_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil akurasi score mengunakan MLP: 0.7532467532467533\n",
      "Hasil roc auc score mengunakan MLP: 0.606140350877193\n",
      "Hasil cross val score mengunakan MLP: 0.7001523386034256\n",
      "Hasil confusion matrix mengunakan MLP:\n",
      " [[52  5]\n",
      " [14  6]]\n",
      "Hasil classification report mengunakan MLP:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.91      0.85        57\n",
      "           2       0.55      0.30      0.39        20\n",
      "\n",
      "    accuracy                           0.75        77\n",
      "   macro avg       0.67      0.61      0.62        77\n",
      "weighted avg       0.72      0.75      0.73        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#validasi dengan metric-metric yang ada\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "a=accuracy_score(y_test, y_tested_mlp)\n",
    "print('Hasil akurasi score mengunakan MLP:',a)\n",
    "\n",
    "\n",
    "b=roc_auc_score(y_test, y_tested_mlp)\n",
    "print('Hasil roc auc score mengunakan MLP:',b)\n",
    "\n",
    "\n",
    "c=cross_val_score(mlp,X,y,cv=10, scoring='roc_auc')\n",
    "print('Hasil cross val score mengunakan MLP:',c.mean())\n",
    "\n",
    "\n",
    "f=confusion_matrix(y_test, y_tested_mlp)\n",
    "print('Hasil confusion matrix mengunakan MLP:\\n',f)\n",
    "\n",
    "\n",
    "g=classification_report(y_test, y_tested_mlp)\n",
    "print('Hasil classification report mengunakan MLP:\\n',g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model yang digunakan lebih akurat dalam memprediksi klas negatif atau yang dapat survive dalam waktu lebih 5 tahun sedangkan untuk memdeteksi yg positif atau peluang pasien survive dibawah 5 tahun masih sangatlah rendah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6v_dgoN-7wL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teekoyIw--g2"
   },
   "source": [
    "<h1> Soal 3: Pemahaman Tentang Model Selection</h1>\n",
    "\n",
    "Jelaskan dengan bahasa sendiri!\n",
    "\n",
    "1. Apa itu Bias dan Variance?\n",
    "2. Apa itu Overfitting dan Underfitting?\n",
    "3. Apa yang bisa kita lakukan untuk mengatur kompleksitas dari model?\n",
    "4. Bagaimana model yang baik?\n",
    "5. Kapan kita menggunakan GridSearchcv dan kapan menggunakan RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4a1l4RNf_FcU"
   },
   "source": [
    "Jawab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bias dan variance\n",
    "    - Bias adalah perbedaan antara rata rata hasil prediksi dari model ML yang kita develop dengan data nilai yang sebenarnya. Bias yang tinggi dikarenakan dalam pembangunan model ML, dilakukan terlalu sederhan (oversimplified). Faktor penyebab lain dikarenakan model ML yang di develop terlalu tidak terlalu berinteraksi dengan training data.\n",
    "    - Variance adalah variabel dari prediksi model untuk data tertentu dimana memberikan kita informasi perserbaran data kita. Model yang memiliki variance tinggi sangat memperhatikan hanya pada train data. High variance model, perform baik di train data. Tetapi jika disuguhkan data baru yang belum pernah ditemukan di train data. Model tersebut tidak dapat mengeneralisasikan secara baik dari identifikasi data baru tersebut. Alhasil model memprediksi dengan keliru.\n",
    "\n",
    "Data yang memiliki Bias yang tinggi dengan variance yang rendah akan menjadi underfitting. Sementara jika dengan bias tinggi dan juga high variance menjadikan prediksi sangat tidak tepat. Jika biasnya rendah dan variancenya tinggi akan menimbulkan overfitting dimana dengan data train, perform baik tapi ketika diberikan data baru, tidak dapat memprediksi. Pastinya yang paling baik jika bias rendah dan variance rendah.\n",
    "\n",
    "2. Overfitting dan Underfitting\n",
    "    - overfitting merupakan kondisi dimana model terlalu presisi terhadap data latih sehingga kemampuan generalisasi yang jelek sehingga ketika mendapati data tes yang baru membuat model gagal mendeksi serta medapat error yang berlebih. Umumnya overfitting memiliki akurasi saat training yang tinggi namun saat test dengan data baru akurasi rendah dan error yang lebih\n",
    "    - Underfitting adalah keadaan dimana model pelatihan data yang dibuat tidak mewakilkan keseluruhan data yang akan digunakan nantinya. Sehingga menghasilkan performa yang buruk dalam pelatihan data. Underfitting terjadi karena model masih mempelajari struktur dari data. Umumnya nilai akurasi saat pelatihan dan pengujian sama-sama rendah.\n",
    "3. yang dapat kita lakukan untuk mengatur kompleksitas dari model adalah menggunakan hyperparameter yang menghasilkan nilai optimum.\n",
    "4. model yang baik ketika akurasi saat training dan saat test sama-sama tinggi, serta presisi dalam memprediksi tiap kelas memiliki akurasi yang sama-sama tinggi\n",
    "5. GridSearchcv digunakan saat kita ingin mendapatkan hyperparameter yang optimum dengan memperthitungkan seluruh peluang kombinasi dari hyperparameter yang diset, sedangkan RandomizedSearchCV mendapatkan hyperparameter yang optimum namun tak seluruhnya memperhitungkan seluruh kombinasi namun kombinasi dipilih berdasarkan jumlah iterasi atau cv yang digunakan kondisi ini bisa sangat cepat mendapatkan nilai optimum hyperparameter namun tetap bergantung jumlah iterasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Svj_cgxF_IZv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hkh-PeRL_LZp"
   },
   "source": [
    "<h1> Soal 4: Aplikasi Model Selection</h1>\n",
    "\n",
    "1. Bagi kedua data berikut ini menjadi data training dan data test dengan test_size=0.25.\n",
    "2. Gunakan algoritma KNN sebagai model classifier.\n",
    "3. Gunakan fungsi GridSearchCV untuk hyperparameter tuning dan model selection.\n",
    "4. jumlah fold bebas!, gunakan scoring 'roc_auc'\n",
    "5. Definisikan kombinasi hyperparameter untuk model selection dengan GridSearchCV. kombinasi Hyperparameter bebas, baca lagi dokumentasi KNN di link berikut https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html untuk memahami lagi jenis2 hyperparameter di algorithma KNN.\n",
    "6. Latih model terhadap data training.\n",
    "7. Apa hyperparameter terbaik untuk kombinasi hyperparameter kalian?\n",
    "8. Berapa score validasi terbaik dari model tersebut?\n",
    "9. Prediksi probabilitasi output dari model yang telah di buat terhadap data test. note : gunakan method .predict_proba() untuk menghasilkan output probabilitas\n",
    "10. Perhatikan bahwa hasil prediksi ada 2, dimana masing2 adalah nilai probabilitas untuk setiap class label. Ambil nilai probabilitas pasien phositive meninggal dalam waktu kurang dari 5 tahun. note : gunakan bantuan attirubte .classes_ untuk mengetahui urutan label dari hasil prediksi probabilitas.\n",
    "11. Berapa nilai score roc_auc untuk data test?\n",
    "12. Apakah model anda termasuk baik, overtting, atau underfitting?\n",
    "13. Ulangi tahap di atas namun kali ini menggunakan algoritma DecisionTreeClassifier dan kalian bisa menggunakan RandomizedSearchCV apabila process training lama. pelajari algoritma DecisionTreeClassifier di linkberikut: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier\n",
    "14. Bandingkan scorenya dengan Algoritma KNN, mana yang lebih baik?\n",
    "\n",
    "Note : Data Science adalah experiment, sangat di dimungkinkan memerlukan beberapa kali percobaan untuk mendapatkan hasil yang terbaik! Happy Coding :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_zK8Mqb-9Z6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qb-AD43R_V_d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Patient's Years  N_positive_ax  survival_status\n",
       "0   30               64              1                1\n",
       "1   30               62              3                1\n",
       "2   30               65              0                1\n",
       "3   31               59              2                1\n",
       "4   31               65              4                1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('survival_status', axis=1)\n",
    "y = df['survival_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znc1dEGO_XU2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil GridSearchCV knn:\n",
      "\n",
      "0.7123424369747899\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
      "                     weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "parameters1 = {'n_neighbors':np.arange(1,21), 'weights':('uniform', 'distance'),\n",
    "                                               'algorithm':('auto', 'ball_tree', 'kd_tree', 'brute')}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid = GridSearchCV(knn, parameters1, cv = 10, scoring = 'roc_auc', return_train_score=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#menampilkan score dan parameter tebaik\n",
    "print ('Hasil GridSearchCV knn:\\n')\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "\n",
    "                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hasil GridSearchCV dtc:\n",
      "\n",
      "0.6764355742296918\n",
      "{'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'splitter': 'best'}\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=1, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "parameters2 = {'criterion':('gini', 'entropy'), 'splitter':('best', 'random'), 'max_depth':np.arange(1,10),\n",
    "                                            'max_features':('auto', 'sqrt', 'log2')}\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "grid2 = GridSearchCV(dtc, parameters2, cv = 10, scoring = 'roc_auc', return_train_score=True)\n",
    "\n",
    "grid2.fit(X_train, y_train)\n",
    "\n",
    "print ('\\n\\nHasil GridSearchCV dtc:\\n')                                                                                                \n",
    "print (grid2.best_score_)\n",
    "print (grid2.best_params_)\n",
    "print (grid2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dari hasil optimasi hyperparameter dengan GridSearchCV model knn mendapati score terbaik 0.7123424369747899 dan untuk dtr  0.6764355742296918."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kombinasi terbaik parameter yang digunakan\n",
    "knn_clf = KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
    "                     weights='distance')\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "dtr_clf = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=1, splitter='best')\n",
    "dtr_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      " [[0.8396757  0.1603243 ]\n",
      " [0.79116585 0.20883415]\n",
      " [0.63461558 0.36538442]\n",
      " [0.         1.        ]\n",
      " [0.67722631 0.32277369]\n",
      " [1.         0.        ]\n",
      " [0.53363999 0.46636001]\n",
      " [0.72937691 0.27062309]\n",
      " [0.85437329 0.14562671]\n",
      " [0.67722631 0.32277369]\n",
      " [0.         1.        ]\n",
      " [1.         0.        ]\n",
      " [0.72819477 0.27180523]\n",
      " [1.         0.        ]\n",
      " [0.84156107 0.15843893]\n",
      " [0.74593908 0.25406092]\n",
      " [0.85534297 0.14465703]\n",
      " [0.68644891 0.31355109]\n",
      " [1.         0.        ]\n",
      " [0.46625569 0.53374431]\n",
      " [0.55174594 0.44825406]\n",
      " [0.84156107 0.15843893]\n",
      " [1.         0.        ]\n",
      " [0.34594814 0.65405186]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [0.6520165  0.3479835 ]\n",
      " [0.58875063 0.41124937]\n",
      " [0.54027675 0.45972325]\n",
      " [0.75282578 0.24717422]\n",
      " [1.         0.        ]\n",
      " [0.         1.        ]\n",
      " [0.76076782 0.23923218]\n",
      " [0.90910942 0.09089058]\n",
      " [0.26511741 0.73488259]\n",
      " [0.77557991 0.22442009]\n",
      " [0.87739809 0.12260191]\n",
      " [0.89572884 0.10427116]\n",
      " [0.56623823 0.43376177]\n",
      " [0.77892892 0.22107108]\n",
      " [0.50948979 0.49051021]\n",
      " [0.5582415  0.4417585 ]\n",
      " [0.72044666 0.27955334]\n",
      " [0.5381423  0.4618577 ]\n",
      " [0.86184105 0.13815895]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [0.91111684 0.08888316]\n",
      " [0.86569458 0.13430542]\n",
      " [0.11893548 0.88106452]\n",
      " [0.72265878 0.27734122]\n",
      " [0.48840625 0.51159375]\n",
      " [0.5347864  0.4652136 ]\n",
      " [0.88753855 0.11246145]\n",
      " [0.50777713 0.49222287]\n",
      " [1.         0.        ]\n",
      " [0.80746967 0.19253033]\n",
      " [0.60703083 0.39296917]\n",
      " [1.         0.        ]\n",
      " [0.11216951 0.88783049]\n",
      " [0.60425151 0.39574849]\n",
      " [0.74679378 0.25320622]\n",
      " [0.87829342 0.12170658]\n",
      " [1.         0.        ]\n",
      " [0.73821865 0.26178135]\n",
      " [0.86302949 0.13697051]\n",
      " [0.65526703 0.34473297]\n",
      " [0.88552339 0.11447661]\n",
      " [0.36667465 0.63332535]\n",
      " [1.         0.        ]\n",
      " [0.34200251 0.65799749]\n",
      " [0.736668   0.263332  ]\n",
      " [1.         0.        ]\n",
      " [0.13275718 0.86724282]\n",
      " [0.73538454 0.26461546]\n",
      " [0.91073193 0.08926807]\n",
      " [0.31169954 0.68830046]]\n",
      "\n",
      "\n",
      "DTR:\n",
      " [[0.78947368 0.21052632]\n",
      " [0.9047619  0.0952381 ]\n",
      " [0.75       0.25      ]\n",
      " [0.         1.        ]\n",
      " [0.75       0.25      ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.78947368 0.21052632]\n",
      " [0.4        0.6       ]\n",
      " [0.92857143 0.07142857]\n",
      " [0.75       0.25      ]\n",
      " [0.75       0.25      ]\n",
      " [0.78947368 0.21052632]\n",
      " [0.62857143 0.37142857]\n",
      " [0.75       0.25      ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.75       0.25      ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.78947368 0.21052632]\n",
      " [0.75       0.25      ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.8        0.2       ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.9047619  0.0952381 ]\n",
      " [0.4        0.6       ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.92857143 0.07142857]\n",
      " [0.9047619  0.0952381 ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.9047619  0.0952381 ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.92857143 0.07142857]\n",
      " [0.75       0.25      ]\n",
      " [0.92857143 0.07142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.92857143 0.07142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.92857143 0.07142857]\n",
      " [1.         0.        ]\n",
      " [0.85714286 0.14285714]\n",
      " [0.75       0.25      ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.75       0.25      ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.75       0.25      ]\n",
      " [0.75       0.25      ]\n",
      " [0.92857143 0.07142857]\n",
      " [0.75       0.25      ]\n",
      " [0.92857143 0.07142857]\n",
      " [0.5        0.5       ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.62857143 0.37142857]\n",
      " [0.4        0.6       ]\n",
      " [0.9047619  0.0952381 ]\n",
      " [0.9047619  0.0952381 ]\n",
      " [0.78947368 0.21052632]\n",
      " [0.62857143 0.37142857]\n",
      " [0.78947368 0.21052632]\n",
      " [0.62857143 0.37142857]\n",
      " [0.75       0.25      ]\n",
      " [0.4        0.6       ]\n",
      " [1.         0.        ]\n",
      " [0.62857143 0.37142857]\n",
      " [0.92857143 0.07142857]\n",
      " [0.78947368 0.21052632]\n",
      " [0.62857143 0.37142857]\n",
      " [0.75       0.25      ]\n",
      " [0.75       0.25      ]\n",
      " [0.62857143 0.37142857]]\n"
     ]
    }
   ],
   "source": [
    "#prediksi probabilitas\n",
    "y_prob1 = knn_clf.predict_proba(X_test)\n",
    "print('KNN:\\n', y_prob1)\n",
    "y_prob2 = dtr_clf.predict_proba(X_test)\n",
    "print('\\n\\nDTR:\\n',y_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1603243 , 0.20883415, 0.36538442, 1.        , 0.32277369,\n",
       "       0.        , 0.46636001, 0.27062309, 0.14562671, 0.32277369,\n",
       "       1.        , 0.        , 0.27180523, 0.        , 0.15843893,\n",
       "       0.25406092, 0.14465703, 0.31355109, 0.        , 0.53374431,\n",
       "       0.44825406, 0.15843893, 0.        , 0.65405186, 0.        ,\n",
       "       0.        , 0.3479835 , 0.41124937, 0.45972325, 0.24717422,\n",
       "       0.        , 1.        , 0.23923218, 0.09089058, 0.73488259,\n",
       "       0.22442009, 0.12260191, 0.10427116, 0.43376177, 0.22107108,\n",
       "       0.49051021, 0.4417585 , 0.27955334, 0.4618577 , 0.13815895,\n",
       "       0.        , 0.        , 0.08888316, 0.13430542, 0.88106452,\n",
       "       0.27734122, 0.51159375, 0.4652136 , 0.11246145, 0.49222287,\n",
       "       0.        , 0.19253033, 0.39296917, 0.        , 0.88783049,\n",
       "       0.39574849, 0.25320622, 0.12170658, 0.        , 0.26178135,\n",
       "       0.13697051, 0.34473297, 0.11447661, 0.63332535, 0.        ,\n",
       "       0.65799749, 0.263332  , 0.        , 0.86724282, 0.26461546,\n",
       "       0.08926807, 0.68830046])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6192982456140352\n",
      "0.5236842105263159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(roc_auc_score(y_test, y_prob1[:,1]))\n",
    "print(roc_auc_score(y_test, y_predik2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saat train:\n",
      "0.9836065573770492\n",
      "0.5618657298985167\n",
      "\n",
      "saat test\n",
      "0.5885964912280702\n",
      "0.5236842105263159\n"
     ]
    }
   ],
   "source": [
    "y_predik1 = knn_clf.predict(X_test)\n",
    "y_predik2 = dtr_clf.predict(X_test)\n",
    "y_trainpredik1 = knn_clf.predict(X_train)\n",
    "y_trainpredik2 = dtr_clf.predict(X_train)\n",
    "\n",
    "print('saat train:')\n",
    "print(roc_auc_score(y_train, y_trainpredik1))\n",
    "print(roc_auc_score(y_train, y_trainpredik2))\n",
    "\n",
    "print('\\nsaat test')\n",
    "print(roc_auc_score(y_test, y_predik1))\n",
    "print(roc_auc_score(y_test, y_predik2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pada model knn terlihat overfitting dimana saat train akurasi sangat tinggi namun saat test data baru akurasi sangat rendah\n",
    "- pada model dtr terlihat underfitting dimana akurasi saat train dan test sama-sama rendah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tugas Hari 3 Pekan 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
